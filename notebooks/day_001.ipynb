{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Copyright 2020 Lima Vallantin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discovering a hidden equation\n",
    "\n",
    "Article: https://vallant.in/difference-machine-learning-software-development/\n",
    "\n",
    "Goal: given the formula: \n",
    "\n",
    "$$ y = (x * 2) + 3 $$ \n",
    "\n",
    "Let's see if we can create a model capable of discovering it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the sets of input and output data\n",
    "input_data = np.array(range(200), dtype=float)\n",
    "output_data = [(i * 2) + 3 for i in input_data]\n",
    "output_data = np.array(output_data, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "layer_0 = tf.keras.layers.Dense(units=1, input_shape=[1])\n",
    "# Assemble the layers and get the model\n",
    "model = tf.keras.Sequential([layer_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=tf.keras.optimizers.Adam(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: loss improved from inf to 41925.57031, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00002: loss improved from 41925.57031 to 38700.35938, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00003: loss improved from 38700.35938 to 35610.65625, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00004: loss improved from 35610.65625 to 32671.03516, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00005: loss improved from 32671.03516 to 29989.72461, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00006: loss improved from 29989.72461 to 27300.04297, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00007: loss improved from 27300.04297 to 24929.35938, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00008: loss improved from 24929.35938 to 22628.08984, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00009: loss improved from 22628.08984 to 20547.24805, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00010: loss improved from 20547.24805 to 18575.31836, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00011: loss improved from 18575.31836 to 16756.08203, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00012: loss improved from 16756.08203 to 15136.86914, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00013: loss improved from 15136.86914 to 13624.22168, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00014: loss improved from 13624.22168 to 12249.10840, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00015: loss improved from 12249.10840 to 11036.13672, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00016: loss improved from 11036.13672 to 9883.91797, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00017: loss improved from 9883.91797 to 8826.56445, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00018: loss improved from 8826.56445 to 7913.58203, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00019: loss improved from 7913.58203 to 7024.72705, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00020: loss improved from 7024.72705 to 6234.46680, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00021: loss improved from 6234.46680 to 5523.45508, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00022: loss improved from 5523.45508 to 4858.69482, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00023: loss improved from 4858.69482 to 4270.84375, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00024: loss improved from 4270.84375 to 3737.13354, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00025: loss improved from 3737.13354 to 3275.29590, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00026: loss improved from 3275.29590 to 2847.59741, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00027: loss improved from 2847.59741 to 2482.07227, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00028: loss improved from 2482.07227 to 2148.58350, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00029: loss improved from 2148.58350 to 1865.50574, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00030: loss improved from 1865.50574 to 1610.75964, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00031: loss improved from 1610.75964 to 1393.81921, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00032: loss improved from 1393.81921 to 1198.05566, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00033: loss improved from 1198.05566 to 1025.46802, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00034: loss improved from 1025.46802 to 878.19318, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00035: loss improved from 878.19318 to 744.95044, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00036: loss improved from 744.95044 to 634.19537, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00037: loss improved from 634.19537 to 534.34760, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00038: loss improved from 534.34760 to 448.56485, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00039: loss improved from 448.56485 to 377.25366, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00040: loss improved from 377.25366 to 315.41776, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00041: loss improved from 315.41776 to 264.15793, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00042: loss improved from 264.15793 to 217.37465, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00043: loss improved from 217.37465 to 180.61609, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00044: loss improved from 180.61609 to 149.46909, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00045: loss improved from 149.46909 to 124.56815, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00046: loss improved from 124.56815 to 102.15768, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00047: loss improved from 102.15768 to 84.11203, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00048: loss improved from 84.11203 to 68.99062, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00049: loss improved from 68.99062 to 56.56076, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00050: loss improved from 56.56076 to 46.07518, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00051: loss improved from 46.07518 to 37.57957, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00052: loss improved from 37.57957 to 30.80237, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00053: loss improved from 30.80237 to 24.86139, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00054: loss improved from 24.86139 to 20.08990, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00055: loss improved from 20.08990 to 16.12265, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00056: loss improved from 16.12265 to 12.86641, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00057: loss improved from 12.86641 to 10.33765, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00058: loss improved from 10.33765 to 8.32491, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00059: loss improved from 8.32491 to 6.69561, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00060: loss improved from 6.69561 to 5.32027, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00061: loss improved from 5.32027 to 4.29416, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00062: loss improved from 4.29416 to 3.44123, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00063: loss improved from 3.44123 to 2.78014, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00064: loss improved from 2.78014 to 2.24202, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00065: loss improved from 2.24202 to 1.82896, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00066: loss improved from 1.82896 to 1.50449, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00067: loss improved from 1.50449 to 1.24517, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00068: loss improved from 1.24517 to 1.04594, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00069: loss improved from 1.04594 to 0.88309, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00070: loss improved from 0.88309 to 0.76076, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00071: loss improved from 0.76076 to 0.66263, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00072: loss improved from 0.66263 to 0.58874, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00073: loss improved from 0.58874 to 0.53123, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00074: loss improved from 0.53123 to 0.48708, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00075: loss improved from 0.48708 to 0.45283, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00076: loss improved from 0.45283 to 0.42661, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00077: loss improved from 0.42661 to 0.40685, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00078: loss improved from 0.40685 to 0.39153, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00079: loss improved from 0.39153 to 0.37998, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00080: loss improved from 0.37998 to 0.37149, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00081: loss improved from 0.37149 to 0.36452, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00082: loss improved from 0.36452 to 0.35948, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00083: loss improved from 0.35948 to 0.35597, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00084: loss improved from 0.35597 to 0.35306, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00085: loss improved from 0.35306 to 0.35096, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00086: loss improved from 0.35096 to 0.34942, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00087: loss improved from 0.34942 to 0.34816, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00088: loss improved from 0.34816 to 0.34730, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00089: loss improved from 0.34730 to 0.34656, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00090: loss improved from 0.34656 to 0.34597, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00091: loss improved from 0.34597 to 0.34550, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00092: loss improved from 0.34550 to 0.34511, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00093: loss improved from 0.34511 to 0.34484, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00094: loss improved from 0.34484 to 0.34440, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00095: loss improved from 0.34440 to 0.34413, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00096: loss improved from 0.34413 to 0.34388, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00097: loss improved from 0.34388 to 0.34361, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00098: loss improved from 0.34361 to 0.34327, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00099: loss improved from 0.34327 to 0.34304, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00100: loss improved from 0.34304 to 0.34277, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00101: loss improved from 0.34277 to 0.34250, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00102: loss improved from 0.34250 to 0.34230, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00103: loss improved from 0.34230 to 0.34207, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00104: loss improved from 0.34207 to 0.34189, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00105: loss improved from 0.34189 to 0.34160, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00106: loss improved from 0.34160 to 0.34141, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00107: loss improved from 0.34141 to 0.34109, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00108: loss improved from 0.34109 to 0.34097, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00109: loss improved from 0.34097 to 0.34059, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00110: loss improved from 0.34059 to 0.34034, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00111: loss improved from 0.34034 to 0.34007, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00112: loss improved from 0.34007 to 0.33985, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00113: loss improved from 0.33985 to 0.33962, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00114: loss improved from 0.33962 to 0.33934, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00115: loss improved from 0.33934 to 0.33906, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00116: loss improved from 0.33906 to 0.33880, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00117: loss improved from 0.33880 to 0.33851, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00118: loss improved from 0.33851 to 0.33824, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00119: loss improved from 0.33824 to 0.33796, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00120: loss improved from 0.33796 to 0.33771, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00121: loss improved from 0.33771 to 0.33740, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00122: loss improved from 0.33740 to 0.33715, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00123: loss improved from 0.33715 to 0.33685, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00124: loss improved from 0.33685 to 0.33660, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00125: loss improved from 0.33660 to 0.33633, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00126: loss improved from 0.33633 to 0.33603, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00127: loss improved from 0.33603 to 0.33582, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00128: loss improved from 0.33582 to 0.33552, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00129: loss improved from 0.33552 to 0.33522, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00130: loss improved from 0.33522 to 0.33497, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00131: loss improved from 0.33497 to 0.33464, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00132: loss improved from 0.33464 to 0.33433, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00133: loss improved from 0.33433 to 0.33402, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00134: loss improved from 0.33402 to 0.33377, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00135: loss improved from 0.33377 to 0.33345, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00136: loss improved from 0.33345 to 0.33318, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00137: loss improved from 0.33318 to 0.33287, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00138: loss improved from 0.33287 to 0.33262, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00139: loss improved from 0.33262 to 0.33231, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00140: loss improved from 0.33231 to 0.33200, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00141: loss improved from 0.33200 to 0.33179, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00142: loss improved from 0.33179 to 0.33145, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00143: loss improved from 0.33145 to 0.33118, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00144: loss improved from 0.33118 to 0.33082, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00145: loss improved from 0.33082 to 0.33050, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00146: loss improved from 0.33050 to 0.33019, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00147: loss improved from 0.33019 to 0.32988, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00148: loss improved from 0.32988 to 0.32960, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00149: loss improved from 0.32960 to 0.32928, saving model to ../models/day1/day1.ckpt\n",
      "\n",
      "Epoch 00150: loss improved from 0.32928 to 0.32894, saving model to ../models/day1/day1.ckpt\n",
      "Finished training the model\n"
     ]
    }
   ],
   "source": [
    "# create callback to save the weights of the trained model\n",
    "checkpoint_path = \"../models/day1/day1.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                              monitor='loss',\n",
    "                                              save_best_only=True,\n",
    "                                              save_weights_only=True,\n",
    "                                              verbose=1\n",
    "                                             )\n",
    "\n",
    "# train model\n",
    "history = model.fit(input_data, \n",
    "                    output_data, \n",
    "                    epochs=150, \n",
    "                    verbose=False,\n",
    "                    callbacks=[callback])\n",
    "\n",
    "print(\"Finished training the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14402aad0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show statistics\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1440327d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load weights and predict\n",
    "# use it to load already trained models\n",
    "checkpoint_path = \"../models/day1/day1.ckpt\"\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the input is 300, the model predicts that the output is 604.45.\n"
     ]
    }
   ],
   "source": [
    "# predict what's the output for the input 300\n",
    "output_300 = model.predict([300])[0][0]\n",
    "print('When the input is 300, the model predicts that the output is {:.2f}.'.format(output_300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the true equation, we see that when the input is 300, the output is 603.00.\n"
     ]
    }
   ],
   "source": [
    "# let's confirm that we are getting a precise output\n",
    "x = 300\n",
    "y = (x * 2) + 3\n",
    "print('Using the true equation, we see that when the input is 300, the output is {:.2f}.'.format(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[2.0086427]], dtype=float32), array([1.8576185], dtype=float32)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the weights for this model\n",
    "layer_0.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
